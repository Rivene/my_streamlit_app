# # # main.py
# # import streamlit as st

# # st.text('hello Streamlit!')

# # youtube_trend_conversation.py
# import streamlit as st
# import requests
# from wordcloud import WordCloud
# import matplotlib.pyplot as plt
# import pandas as pd
# import re
# from collections import Counter
# # :ì—´ì‡ ì™€_ìž ê¸´_ìžë¬¼ì‡ : ìœ íŠœë¸Œ API í‚¤ (â† ë³¸ì¸ì˜ í‚¤ë¡œ ë³€ê²½)
# API_KEY = "AIzaSyCHDXTtIcfegyjBplVooLoeBud1dkchfGA"
# # :ì•žìª½_í™”ì‚´í‘œ: ì±„ë„ ID ìž…ë ¥ ë°›ê¸°
# st.set_page_config(page_title="YouTube íŠ¸ë Œë“œ & ëŒ€í™” ì£¼ì œ ë¶„ì„ê¸°", page_icon=":í´ëž˜í¼:", layout="wide")
# st.title("ðŸŽ¬: ìœ íŠœë¸Œ ì¸ê¸° íŠ¸ë Œë“œ ë¶„ì„ & ëŒ€í™” ì£¼ì œ ì¶”ì²œ")
# st.write("ìœ íŠœë¸Œ ì±„ë„ì˜ ì¸ê¸° ì˜ìƒì„ ë¶„ì„í•´ í‚¤ì›Œë“œì™€ ëŒ€í™” ì£¼ì œë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.")
# channel_id = st.text_input("ðŸ“º: ìœ íŠœë¸Œ ì±„ë„ ID", help="ì˜ˆ: UC_x5XG1OV2P6uZZ5FSM9Ttw")
# video_count = st.slider("ðŸŽž: ë¶„ì„í•  ì˜ìƒ ê°œìˆ˜", 5, 20, 10)
# # :ë¹—ìžë£¨: í…ìŠ¤íŠ¸ ì •ì œ

# def clean_text(text):
#     text = re.sub(r"[^\uAC00-\uD7A3a-zA-Z0-9\s]", "", text)
#     return text.lower()

# # :ëŒ€ë¬¸ìž_abcd: í‚¤ì›Œë“œ ì¶”ì¶œ (í•œê¸€ 2ê¸€ìž ì´ìƒë§Œ)
# def extract_keywords(texts, top_n=30):
#     all_words = []
#     for text in texts:
#         # í•œê¸€ 2ê¸€ìž ì´ìƒë§Œ ì¶”ì¶œ
#         words = re.findall(r'[ê°€-íž£]{2,}', clean_text(text))
#         all_words.extend(words)
#     return Counter(all_words).most_common(top_n)

# # :êµ¬ë¦„: ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± (í•œê¸€ í°íŠ¸ ì§€ì •)
# def create_wordcloud(freq_dict):
#     wc = WordCloud(font_path="nanumgothic.ttf", background_color="white", width=800, height=400)
#     wc.generate_from_frequencies(freq_dict)
#     return wc
# # :ì‹œê³„_ë°˜ëŒ€_ë°©í–¥_í™”ì‚´í‘œ: ì±„ë„ â†’ ì—…ë¡œë“œ ë¦¬ìŠ¤íŠ¸ ID
# def get_upload_playlist_id(channel_id):
#     url = f"https://www.googleapis.com/youtube/v3/channels?part=contentDetails&id={channel_id}&key={API_KEY}"
#     res = requests.get(url).json()
#     try:
#         return res['items'][0]['contentDetails']['relatedPlaylists']['uploads']
#     except:
#         return None
# # :ë°›ì€_íŽ¸ì§€í•¨_íŠ¸ë ˆì´: ì—…ë¡œë“œ ë¦¬ìŠ¤íŠ¸ â†’ ì˜ìƒ ì •ë³´
# def get_videos_from_playlist(playlist_id, max_results):
#     url = f"https://www.googleapis.com/youtube/v3/playlistItems?part=snippet&playlistId={playlist_id}&maxResults={max_results}&key={API_KEY}"
#     res = requests.get(url).json()
#     videos = []
#     for item in res.get("items", []):
#         snippet = item["snippet"]
#         videos.append({
#             "video_id": snippet["resourceId"]["videoId"],
#             "title": snippet["title"],
#             "description": snippet["description"],
#             "url": f"https://www.youtube.com/watch?v={snippet['resourceId']['videoId']}"
#         })
#     return videos
# # :ë§í’ì„ : ëŒ€í™” ì£¼ì œ ìƒì„±
# def generate_conversation_topics(keywords):
#     prompts = []
#     for keyword, _ in keywords[:10]:
#         if "ê²Œìž„" in keyword:
#             prompts.append(f"ðŸŽ®: ìš”ì¦˜ '{keyword}' ê´€ë ¨ ì½˜í…ì¸  ë§Žì´ ë³´ì´ë˜ë°, ì¦ê²¨ í•˜ì„¸ìš”?")
#         elif "ì—¬í–‰" in keyword or "íœ´ê°€" in keyword:
#             prompts.append(f"âœˆï¸: '{keyword}' ê´€ë ¨ ì˜ìƒì´ ì¸ê¸°ì¸ë°, ìµœê·¼ì— ì–´ë”” ë‹¤ë…€ì˜¤ì…¨ì–´ìš”?")
#         elif "ìŒì•…" in keyword or "ë…¸ëž˜" in keyword:
#             prompts.append(f"ðŸŽµ: '{keyword}' ì˜ìƒì´ ë§Žì€ë°, ì–´ë–¤ ìŒì•… ì¢‹ì•„í•˜ì„¸ìš”?")
#         elif "ë‹¤ì´ì–´íŠ¸" in keyword or "í—¬ìŠ¤" in keyword:
#             prompts.append(f"ðŸ’ª: '{keyword}' ê´€ë ¨í•œ ì˜ìƒì´ ë§Žë„¤ìš”. ê±´ê°•ê´€ë¦¬ ì–´ë–»ê²Œ í•˜ì„¸ìš”?")
#         elif "ë“œë¼ë§ˆ" in keyword or "ì˜í™”" in keyword:
#             prompts.append(f"ðŸŽ¬: '{keyword}' ì˜ìƒì´ í•«í•œë°, í˜¹ì‹œ ìµœê·¼ ë³¸ ê±° ìžˆìœ¼ì„¸ìš”?")
#         else:
#             prompts.append(f"ðŸ—£ï¸: '{keyword}' ìš”ì¦˜ í•«í•œ ì£¼ì œ ê°™ì•„ìš”. ì–´ë–»ê²Œ ìƒê°í•˜ì„¸ìš”?")
#     return prompts[:5]
# # :ë¡œì¼“: ë¶„ì„ ì‹œìž‘
# if st.button(": íŠ¸ë Œë“œ ë¶„ì„ ì‹œìž‘"):
#     if not channel_id:
#         st.error("ì±„ë„ IDë¥¼ ìž…ë ¥í•´ì£¼ì„¸ìš”.")
#     else:
#         with st.spinner("YouTube ì±„ë„ ì •ë³´ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
#             playlist_id = get_upload_playlist_id(channel_id)
#         if not playlist_id:
#             st.error("ì±„ë„ IDê°€ ìž˜ëª»ë˜ì—ˆê±°ë‚˜ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
#         else:
#             with st.spinner("ì¸ê¸° ì˜ìƒ ë¶„ì„ ì¤‘..."):
#                 videos = get_videos_from_playlist(playlist_id, video_count)
#             if not videos:
#                 st.warning("ì˜ìƒì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#             else:
#                 titles = [v["title"] for v in videos]
#                 descriptions = [v["description"] for v in videos]
#                 texts = titles + descriptions
#                 keywords = extract_keywords(texts)
#                 keyword_df = pd.DataFrame(keywords)
#                 keyword_df.columns = ["í‚¤ì›Œë“œ", "ë¹ˆë„"]
#                 # :êµ¬ë¦„: ì›Œë“œí´ë¼ìš°ë“œ
#                 st.subheader("â˜ï¸: ì›Œë“œí´ë¼ìš°ë“œ")
#                 fig, ax = plt.subplots(figsize=(10, 5))
#                 wc = create_wordcloud(dict(keywords))
#                 ax.imshow(wc, interpolation="bilinear")
#                 ax.axis("off")
#                 st.pyplot(fig)
#                 # :ë§‰ëŒ€_ì°¨íŠ¸: í‚¤ì›Œë“œ ë°” ì°¨íŠ¸
#                 st.subheader("ðŸ“Š: í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜")
#                 st.bar_chart(keyword_df.set_index("í‚¤ì›Œë“œ"))
#                 # :ë§í’ì„ : ëŒ€í™” ì£¼ì œ ì¶”ì²œ
#                 st.subheader("ðŸ’¬: ì¶”ì²œ ëŒ€í™” ì£¼ì œ")
#                 topics = generate_conversation_topics(keywords)
#                 for i, t in enumerate(topics, 1):
#                     st.write(f"**{i}.** {t}")
#                 # :í•„ë¦„_í”„ë ˆìž„: ì˜ìƒ ëª©ë¡
#                 st.subheader("ðŸŽ¥: ì¸ê¸° ì˜ìƒ ëª©ë¡")
#                 for v in videos:
#                     st.markdown(f"- [{v['title']}]({v['url']})")
#                 # :ë°›ì€_íŽ¸ì§€í•¨_íŠ¸ë ˆì´: ë‹¤ìš´ë¡œë“œ
#                 st.subheader("ðŸ“¥: ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")
#                 csv = keyword_df.to_csv(index=False)
#                 st.download_button("ðŸ“„:ê¸€ì”¨ê°€_ì“°ì—¬ì§„_íŽ˜ì´ì§€: í‚¤ì›Œë“œ CSV ë‹¤ìš´ë¡œë“œ", csv, "youtube_trend_keywords.csv", mime="text/csv")
#                 txt = "\n".join(topics)
#                 st.download_button("ðŸ’¬: ëŒ€í™” ì£¼ì œ TXT ë‹¤ìš´ë¡œë“œ", txt, "youtube_conversation_topics.txt", mime="text/plain")


import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ 
# py -m pip install plotly 

# íŽ˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="íŒë§¤ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ðŸ“Š",
    layout="wide"
)

@st.cache_data
def generate_sample_data():
    """ìƒ˜í”Œ íŒë§¤ ë°ì´í„° ìƒì„±"""
    np.random.seed(42)
    
    # ë‚ ì§œ ë²”ìœ„
    start_date = datetime(2023, 1, 1)
    end_date = datetime(2023, 12, 31)
    dates = pd.date_range(start_date, end_date, freq='D')
    
    # ì œí’ˆ ì¹´í…Œê³ ë¦¬
    categories = ['ì „ìžì œí’ˆ', 'ì˜ë¥˜', 'ê°€êµ¬', 'ë„ì„œ', 'ìŠ¤í¬ì¸ ']
    regions = ['ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼']
    
    data = []
    for date in dates:
        for category in categories:
            for region in regions:
                sales = np.random.normal(1000, 300)
                quantity = np.random.poisson(50)
                data.append({
                    'date': date,
                    'category': category,
                    'region': region,
                    'sales': max(0, sales),
                    'quantity': quantity
                })
    
    return pd.DataFrame(data)

def main():
    st.title("ðŸ“Š íŒë§¤ ë°ì´í„° ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
    
    # ì‚¬ì´ë“œë°”
    st.sidebar.title("í•„í„° ì˜µì…˜")
    
    # ë°ì´í„° ë¡œë“œ
    df = generate_sample_data()
    
    # ë‚ ì§œ í•„í„°
    date_range = st.sidebar.date_input(
        "ê¸°ê°„ ì„ íƒ",
        value=[df['date'].min(), df['date'].max()],
        min_value=df['date'].min(),
        max_value=df['date'].max()
    )
    
    # ì¹´í…Œê³ ë¦¬ í•„í„°
    categories = st.sidebar.multiselect(
        "ì¹´í…Œê³ ë¦¬ ì„ íƒ",
        options=df['category'].unique(),
        default=df['category'].unique()
    )
    
    # ì§€ì—­ í•„í„°
    regions = st.sidebar.multiselect(
        "ì§€ì—­ ì„ íƒ",
        options=df['region'].unique(),
        default=df['region'].unique()
    )
    
    # ë°ì´í„° í•„í„°ë§
    if len(date_range) == 2:
        filtered_df = df[
            (df['date'] >= pd.Timestamp(date_range[0])) &
            (df['date'] <= pd.Timestamp(date_range[1])) &
            (df['category'].isin(categories)) &
            (df['region'].isin(regions))
        ]
    else:
        filtered_df = df[
            (df['category'].isin(categories)) &
            (df['region'].isin(regions))
        ]
    
    # ì£¼ìš” ì§€í‘œ
    st.subheader("ðŸ“ˆ ì£¼ìš” ì§€í‘œ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_sales = filtered_df['sales'].sum()
        st.metric("ì´ ë§¤ì¶œ", f"â‚©{total_sales:,.0f}")
    
    with col2:
        total_quantity = filtered_df['quantity'].sum()
        st.metric("ì´ íŒë§¤ëŸ‰", f"{total_quantity:,}")
    
    with col3:
        avg_sales = filtered_df['sales'].mean()
        st.metric("í‰ê·  ì¼ì¼ ë§¤ì¶œ", f"â‚©{avg_sales:,.0f}")
    
    with col4:
        unique_days = filtered_df['date'].nunique()
        st.metric("ë¶„ì„ ê¸°ê°„", f"{unique_days}ì¼")
    
    # ì°¨íŠ¸ ì„¹ì…˜
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ðŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ")
        category_sales = filtered_df.groupby('category')['sales'].sum().reset_index()
        fig_pie = px.pie(category_sales, values='sales', names='category', 
                        title="ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¶œ ë¹„ìœ¨")
        st.plotly_chart(fig_pie, use_container_width=True)
    
    with col2:
        st.subheader("ðŸŒ ì§€ì—­ë³„ ë§¤ì¶œ")
        region_sales = filtered_df.groupby('region')['sales'].sum().reset_index()
        fig_bar = px.bar(region_sales, x='region', y='sales', 
                        title="ì§€ì—­ë³„ ì´ ë§¤ì¶œ")
        st.plotly_chart(fig_bar, use_container_width=True)
    
    # ì‹œê³„ì—´ ì°¨íŠ¸
    st.subheader("ðŸ“ˆ ì‹œê°„ë³„ ë§¤ì¶œ ì¶”ì´")
    
    daily_sales = filtered_df.groupby('date')['sales'].sum().reset_index()
    fig_line = px.line(daily_sales, x='date', y='sales', 
                      title="ì¼ë³„ ë§¤ì¶œ ì¶”ì´")
    st.plotly_chart(fig_line, use_container_width=True)
    
    # ìƒì„¸ ë°ì´í„° í…Œì´ë¸”
    with st.expander("ðŸ“‹ ìƒì„¸ ë°ì´í„° ë³´ê¸°"):
        st.dataframe(filtered_df.sort_values('date', ascending=False), 
                    use_container_width=True)
        
        # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
        csv = filtered_df.to_csv(index=False)
        st.download_button(
            label="í•„í„°ë§ëœ ë°ì´í„° ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name=f'sales_data_{datetime.now().strftime("%Y%m%d")}.csv',
            mime='text/csv'
        )
    
    # ë¶„ì„ ë¦¬í¬íŠ¸
    st.subheader("ðŸ“ ë¶„ì„ ë¦¬í¬íŠ¸")
    
    # ìµœê³  ì‹¤ì  ì¹´í…Œê³ ë¦¬
    best_category = category_sales.loc[category_sales['sales'].idxmax(), 'category']
    best_region = region_sales.loc[region_sales['sales'].idxmax(), 'region']
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info(f"**ìµœê³  ì‹¤ì  ì¹´í…Œê³ ë¦¬:** {best_category}")
        st.info(f"**ìµœê³  ì‹¤ì  ì§€ì—­:** {best_region}")
    
    with col2:
        peak_day = daily_sales.loc[daily_sales['sales'].idxmax(), 'date']
        st.info(f"**ìµœê³  ë§¤ì¶œì¼:** {peak_day.strftime('%Y-%m-%d')}")
        st.info(f"**ë¶„ì„ ê¸°ê°„ í‰ê·  ì¼ì¼ ë§¤ì¶œ:** â‚©{daily_sales['sales'].mean():,.0f}")

if __name__ == "__main__":
    main()